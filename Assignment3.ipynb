{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDS 576: Assignment 3\n",
    "\n",
    "- Turn in solutions as a single notebook (ipynb) and as a pdf on Blackboard. No need to turn in datasets/word-docs.\n",
    "- Answer the following questions concisely, in complete sentences and with full clarity. If in doubt, ask classmates and the teaching staff. Across group collaboration is not allowed. Always cite all your sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RNN for Language Modeling (4pt)\n",
    "\n",
    " -  Import the torchtext IMDB dataset and do the following:\n",
    "   -  Build a  Markov (n-gram) language model.\n",
    "   -  Change the output and the model appropriately in [Seq2Seq_LSTM_Simple_Sentiment_Analysis.ipynb](https://github.com/thejat/dl-notebooks/blob/master/examples/recurrent_neural_networks/Seq2Seq_LSTM_Simple_Sentiment_Analysis.ipynb) (old: [Simple Sentiment Analysis.ipynb](https://github.com/bentrevett/pytorch-sentiment-analysis)) to build an LSTM based language model. Plot the training performance as a function of epochs/iterations.\n",
    " -  For each model, describe the key design choices made. Briefly mention how each choice influences training time and generative quality.\n",
    " -  For each model, starting with the phrase \"My favorite movie \", sample the next few words and create an approx. 20 word generated review. Repeat this 5 times (you should ideally get different outputs each time) and report the outputs.\n",
    " - Note: make any assumptions as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sequence to Sequence Model for Translation (4pt)\n",
    "\n",
    " -  Train a sequence to sequence model (Model 1) building on [an example notebook](https://github.com/thejat/dl-notebooks/blob/master/examples/rexamples/recurrent_neural_networks/Seq2Seq_Translation_Example.ipynb) (also available [here](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)) for a language pair (excluding French-English), where the output is English and the input is a language of [your choice](https://www.manythings.org/anki/).\n",
    " -  Now train another model (Model 2) for the reverse (i.e., from English to the language you chose). In this model, use the GloVe 100 dimensional embeddings for the English portion. Use [Fasttext](https://fasttext.cc/docs/en/crawl-vectors.html) embeddings for the other language if needed.\n",
    " -  Input 5 well formed sentences in English to Model 2, and input the resultant translated sentences to Model 1. Display all model outputs in each case.\n",
    " - Note: make any assumptions as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
